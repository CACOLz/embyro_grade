import streamlit as st
import torch
from torchvision import models, transforms
from PIL import Image
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
import joblib
from scipy.stats import entropy
from transformers import ViTForImageClassification, ViTImageProcessor, ViTConfig
import cv2
from skimage import measure
import os

# ------------------------ Configuration ------------------------

# í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì–»ê¸°
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# Path to the saved RandomForestClassifier and Scaler
RANDOM_FOREST_MODEL_PATH = os.path.join(BASE_DIR, 'random_forest_model.pkl')
SCALER_PATH = os.path.join(BASE_DIR, 'scaler.pkl')

# Probability and Entropy thresholds
PROB_THRESHOLD = 0.4
ENTROPY_THRESHOLD = 1.4

# Device configuration
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# ------------------------ Load Models ------------------------

@st.cache_resource
def load_models():
    # Check if model files exist
    if not os.path.exists(RANDOM_FOREST_MODEL_PATH):
        st.error(f"RandomForestClassifier ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: '{RANDOM_FOREST_MODEL_PATH}'")
        return None, None, None, None, None
    
    if not os.path.exists(SCALER_PATH):
        st.error(f"Scaler íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: '{SCALER_PATH}'")
        return None, None, None, None, None

    # Load Inception-v3 model with weights
    inception_weights = models.Inception_V3_Weights.IMAGENET1K_V1
    inception_model = models.inception_v3(weights=inception_weights, aux_logits=True)
    inception_model.fc = torch.nn.Identity()
    inception_model.AuxLogits = torch.nn.Identity()
    inception_model.to(DEVICE)
    inception_model.eval()

    # Load ViT ëª¨ë¸
    config = ViTConfig.from_pretrained('google/vit-base-patch16-224', num_labels=5)
    model_vit = ViTForImageClassification.from_pretrained(
        'google/vit-base-patch16-224',
        config=config,
        ignore_mismatched_sizes=True
    )
    model_vit.to(DEVICE)
    model_vit.eval()

    # Load Feature Extractor for ViT
    feature_extractor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')

    # Load RandomForestClassifier and Scaler
    rf_classifier = joblib.load(RANDOM_FOREST_MODEL_PATH)
    scaler = joblib.load(SCALER_PATH)

    return inception_model, model_vit, feature_extractor, rf_classifier, scaler

# Load models
inception_model, model_vit, feature_extractor, rf_classifier, scaler = load_models()

if inception_model is None or model_vit is None or feature_extractor is None or rf_classifier is None or scaler is None:
    st.stop()

# ------------------------ Define Transforms ------------------------

preprocess_inception = transforms.Compose([
    transforms.Resize(299),
    transforms.CenterCrop(299),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],  # ImageNet í‰ê· ê°’
        std=[0.229, 0.224, 0.225]    # ImageNet í‘œì¤€í¸ì°¨
    )
])

# ------------------------ Helper Functions ------------------------

def extract_morphological_features(image):
    """
    ì´ë¯¸ì§€ì—ì„œ í˜•íƒœí•™ì  íŠ¹ì§•ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Parameters:
        image (PIL.Image): ì´ë¯¸ì§€ ê°ì²´.
    
    Returns:
        list: [blastocyst_area, icm_area, circularity, blastocyst_density, perimeter_to_area_ratio]
    """
    # PIL ì´ë¯¸ì§€ë¥¼ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    image_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
    if image_cv is None:
        st.warning("ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return [0, 0, 0, 0, 0]
    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
    gray = cv2.cvtColor(image_cv, cv2.COLOR_BGR2GRAY)
    # ì´ì§„í™”
    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

    # ë¼ë²¨ë§ì„ í†µí•´ ê°ì²´ ë¶„í• 
    labels = measure.label(thresh, connectivity=2)
    properties = measure.regionprops(labels)

    # ë°°ë°˜í¬ ì „ì²´ ì˜ì—­ ì¶”ì¶œ
    if properties:
        # ê°€ì¥ í° ê°ì²´ë¥¼ ë°°ë°˜í¬ë¡œ ê°„ì£¼
        largest_contour = max(properties, key=lambda x: x.area)
        blastocyst_area = largest_contour.area
        blastocyst_perimeter = largest_contour.perimeter

        # TE í’ˆì§ˆ: ì›í˜•ë„ ê³„ì‚°
        circularity = (4 * np.pi * blastocyst_area) / (blastocyst_perimeter ** 2) if blastocyst_perimeter != 0 else 0

        # ICM ì¶”ì¶œ: ë°°ë°˜í¬ ë‚´ë¶€ì˜ ê°€ì¥ í° ê°ì²´ë¥¼ ICMìœ¼ë¡œ ê°„ì£¼
        mask = labels == largest_contour.label
        masked_image = np.where(mask, gray, 0)
        _, inner_thresh = cv2.threshold(masked_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        inner_labels = measure.label(inner_thresh, connectivity=2)
        inner_properties = measure.regionprops(inner_labels)

        if inner_properties:
            icm = max(inner_properties, key=lambda x: x.area)
            icm_area = icm.area
        else:
            icm_area = 0

        # ì¶”ê°€ì ì¸ í˜•íƒœí•™ì  íŠ¹ì§• ê³„ì‚°
        blastocyst_density = icm_area / blastocyst_area if blastocyst_area != 0 else 0
        perimeter_to_area_ratio = blastocyst_perimeter / blastocyst_area if blastocyst_area != 0 else 0

        return [blastocyst_area, icm_area, circularity, blastocyst_density, perimeter_to_area_ratio]
    else:
        # ê°ì²´ê°€ ì—†ì„ ê²½ìš° 0ìœ¼ë¡œ ì±„ì›€
        return [0, 0, 0, 0, 0]

def extract_inception_features(image, model, preprocess, device):
    """
    InceptionV3ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ ë”¥ëŸ¬ë‹ íŠ¹ì§•ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Parameters:
        image (PIL.Image): ì´ë¯¸ì§€ ê°ì²´.
        model (torch.nn.Module): InceptionV3 ëª¨ë¸.
        preprocess (torchvision.transforms.Compose): ì „ì²˜ë¦¬ ë³€í™˜.
        device (torch.device): ë””ë°”ì´ìŠ¤.
    
    Returns:
        np.ndarray: ì¶”ì¶œëœ íŠ¹ì§• ë²¡í„°.
    """
    input_tensor = preprocess(image)
    input_batch = input_tensor.unsqueeze(0).to(device)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ ë° ë””ë°”ì´ìŠ¤ ì´ë™

    with torch.no_grad():
        # ì¤‘ê°„ ë ˆì´ì–´ì˜ ì¶œë ¥ì„ ì–»ê¸° ìœ„í•´ hook ì‚¬ìš©
        features = []

        def hook(module, input, output):
            features.append(output.cpu().numpy())

        # 'avgpool' ë ˆì´ì–´ì— hook ë“±ë¡
        handle = model.avgpool.register_forward_hook(hook)
        model(input_batch)
        handle.remove()

    if features:
        features_array = features[0].flatten()
        return features_array
    else:
        return np.array([])

def extract_vit_features(image, model_vit, feature_extractor, device):
    """
    ViTë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ ë”¥ëŸ¬ë‹ íŠ¹ì§•ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Parameters:
        image (PIL.Image): ì´ë¯¸ì§€ ê°ì²´.
        model_vit (transformers.ViTForImageClassification): ViT ëª¨ë¸.
        feature_extractor (transformers.ViTImageProcessor): ViT íŠ¹ì§• ì¶”ì¶œê¸°.
        device (torch.device): ë””ë°”ì´ìŠ¤.
    
    Returns:
        np.ndarray: ì¶”ì¶œëœ íŠ¹ì§• ë²¡í„°.
    """
    encoding = feature_extractor(images=image, return_tensors='pt')
    input_ids = encoding['pixel_values'].to(device)

    with torch.no_grad():
        outputs = model_vit(input_ids)
        logits = outputs.logits
        probs = torch.softmax(logits, dim=1)
        features = probs.cpu().numpy().flatten()

    return features

# ------------------------ Streamlit App ------------------------

def main():
    st.title("Blastocyst Grade Classification")
    st.write("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ Gradeë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤. ë¶ˆí™•ì‹¤í•œ ì˜ˆì¸¡ì€ ê²€í†  ëŒ€ìƒìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤.")

    uploaded_files = st.file_uploader("ì´ë¯¸ì§€ íŒŒì¼ ì—…ë¡œë“œ", type=['png', 'jpg', 'jpeg'], accept_multiple_files=True)

    if uploaded_files:
        results = []

        for uploaded_file in uploaded_files:
            image = Image.open(uploaded_file).convert('RGB')
            st.image(image, caption=f"Uploaded Image: {uploaded_file.name}", use_column_width=True)

            # 1. í˜•íƒœí•™ì  íŠ¹ì§• ì¶”ì¶œ
            morph_features = extract_morphological_features(image)

            # 2. InceptionV3 íŠ¹ì§• ì¶”ì¶œ
            inception_features = extract_inception_features(image, inception_model, preprocess_inception, DEVICE)
            if inception_features.size == 0:
                inception_features = np.zeros(2048)

            # 3. ViT íŠ¹ì§• ì¶”ì¶œ
            vit_features = extract_vit_features(image, model_vit, feature_extractor, DEVICE)
            if vit_features.size == 0:
                vit_features = np.zeros(5)

            # 4. íŠ¹ì§• ê²°í•©
            combined_features = list(morph_features) + list(inception_features) + list(vit_features)

            # 5. íŠ¹ì§• ìŠ¤ì¼€ì¼ë§
            combined_features_scaled = scaler.transform([combined_features])

            # 6. ì˜ˆì¸¡ í´ë˜ìŠ¤ í™•ë¥ 
            probabilities = rf_classifier.predict_proba(combined_features_scaled)[0]

            # 7. ì˜ˆì¸¡ í´ë˜ìŠ¤
            predicted_class = rf_classifier.predict(combined_features_scaled)[0]

            # 8. í™•ë¥  ì„ê³„ê°’ê³¼ ì—”íŠ¸ë¡œí”¼ ê¸°ì¤€ì— ë”°ë¼ 'Reviewed' ì—¬ë¶€ ê²°ì •
            max_prob = np.max(probabilities)
            image_entropy = entropy(probabilities)
            if max_prob > PROB_THRESHOLD or image_entropy > ENTROPY_THRESHOLD:
                reviewed = True
            else:
                reviewed = False

            # 9. ê²°ê³¼ ì €ì¥
            result = {
                'Image': uploaded_file.name,
                'Predicted_Class': predicted_class,
                'Probability_Class_1': probabilities[0],
                'Probability_Class_2': probabilities[1],
                'Probability_Class_3': probabilities[2],
                'Probability_Class_4': probabilities[3],
                'Probability_Class_5': probabilities[4],
                'Entropy': image_entropy,
                'Reviewed': reviewed
            }
            results.append(result)

            # 10. ê²°ê³¼ í‘œì‹œ
            st.markdown(f"**Predicted Class:** {predicted_class}")
            st.markdown(f"**Probabilities:**")
            st.write(pd.DataFrame(probabilities.reshape(1, -1), columns=['Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5']))
            st.markdown(f"**Entropy:** {image_entropy:.2f}")
            if reviewed:
                st.warning("ğŸ”´ ì´ ì´ë¯¸ì§€ëŠ” ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            else:
                st.success("ğŸŸ¢ ì´ ì´ë¯¸ì§€ëŠ” ì •ìƒì ìœ¼ë¡œ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.markdown("---")

        # 11. ì „ì²´ ê²°ê³¼ë¥¼ CSVë¡œ ë‹¤ìš´ë¡œë“œ
        if st.button("ì „ì²´ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ"):
            results_df = pd.DataFrame(results)
            csv = results_df.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="CSV íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                data=csv,
                file_name='classification_results.csv',
                mime='text/csv',
            )

if __name__ == "__main__":
    main()
